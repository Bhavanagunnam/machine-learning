{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/9izb8uVs5aEy+p0goT38",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhavanagunnam/machine-learning/blob/main/id3_algorithmexp3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xkj6lLZGAa0q",
        "outputId": "e950cd33-9bd1-4574-b361-4c96ca7b36aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Factorized dataset:\n",
            "    Outlook  Temperature  Humidity  Windy  PlayTennis\n",
            "0         0            0         0      0           0\n",
            "1         0            0         0      1           0\n",
            "2         1            0         0      0           1\n",
            "3         2            1         0      0           1\n",
            "4         2            1         1      0           1\n",
            "5         2            1         1      1           0\n",
            "6         1            1         1      1           1\n",
            "7         0            0         1      0           0\n",
            "8         0            1         0      0           1\n",
            "9         2            1         0      1           0\n",
            "10        0            2         0      1           1\n",
            "11        1            0         1      0           1\n",
            "12        1            0         0      1           1\n",
            "The tree structure:\n",
            "{'Outlook': {0: {'Temperature': {0: 0, 1: 1, 2: 1}},\n",
            "             1: 1,\n",
            "             2: {'Windy': {0: 1, 1: 0}}}}\n",
            "The classification for the new sample is: No\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from collections import Counter\n",
        "\n",
        "# ID3 algorithm implementation\n",
        "def id3(df, target_attribute, attribute_names, default_class=None):\n",
        "    cnt = Counter(x for x in df[target_attribute])\n",
        "\n",
        "    # If the target attribute has only one unique value, return that value\n",
        "    if len(cnt) == 1:\n",
        "        return next(iter(cnt))\n",
        "\n",
        "    # If the dataset is empty or attribute_names list is empty, return the default class\n",
        "    elif df.empty or (not attribute_names):\n",
        "        return default_class\n",
        "\n",
        "    else:\n",
        "        # Calculate information gain for each attribute\n",
        "        gainz = mutual_info_classif(df[attribute_names], df[target_attribute],\n",
        "                                    discrete_features=True)\n",
        "        index_of_max = gainz.tolist().index(max(gainz))\n",
        "        best_attr = attribute_names[index_of_max]\n",
        "\n",
        "        # Create a new decision tree node with the best attribute\n",
        "        tree = {best_attr: {}}\n",
        "\n",
        "        # Remove the best attribute from the list of attributes\n",
        "        remaining_attribute_names = [i for i in attribute_names if i != best_attr]\n",
        "\n",
        "        # Recursively create subtrees for each value of the best attribute\n",
        "        for attr_val, data_subset in df.groupby(best_attr):\n",
        "            subtree = id3(data_subset, target_attribute, remaining_attribute_names, default_class)\n",
        "            tree[best_attr][attr_val] = subtree\n",
        "\n",
        "        return tree\n",
        "\n",
        "# Function to classify a new sample\n",
        "def classify(tree, sample):\n",
        "    if not isinstance(tree, dict):\n",
        "        return tree\n",
        "    attr = next(iter(tree))\n",
        "    if sample[attr] in tree[attr]:\n",
        "        return classify(tree[attr][sample[attr]], sample)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Create the dataset from the provided data\n",
        "data = {\n",
        "    \"Outlook\": [\"Sunny\", \"Sunny\", \"Overcast\", \"Rain\", \"Rain\", \"Rain\", \"Overcast\", \"Sunny\",\n",
        "                \"Sunny\", \"Rain\", \"Sunny\", \"Overcast\", \"Overcast\"],\n",
        "    \"Temperature\": [\"Hot\", \"Hot\", \"Hot\", \"Mild\", \"Mild\", \"Mild\", \"Mild\", \"Hot\", \"Mild\",\n",
        "                    \"Mild\", \"Overcast\", \"Hot\", \"Hot\"],\n",
        "    \"Humidity\": [\"High\", \"High\", \"High\", \"High\", \"Normal\", \"Normal\", \"Normal\", \"Normal\",\n",
        "                 \"High\", \"High\", \"High\", \"Normal\", \"High\"],\n",
        "    \"Windy\": [\"FALSE\", \"TRUE\", \"FALSE\", \"FALSE\", \"FALSE\", \"TRUE\", \"TRUE\",\n",
        "              \"FALSE\", \"FALSE\", \"TRUE\", \"TRUE\", \"FALSE\", \"TRUE\"],\n",
        "    \"PlayTennis\": [\"No\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"Yes\", \"No\", \"Yes\", \"No\", \"Yes\",\n",
        "                   \"Yes\", \"Yes\"]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Extract attribute names and remove the target attribute\n",
        "attribute_names = df.columns.tolist()\n",
        "attribute_names.remove(\"PlayTennis\")\n",
        "\n",
        "# Factorize categorical columns and store the mappings\n",
        "factor_mappings = {}\n",
        "for colname in df.select_dtypes(\"object\"):\n",
        "    df[colname], mapping = df[colname].factorize()\n",
        "    factor_mappings[colname] = mapping\n",
        "\n",
        "# Print the factorized dataset\n",
        "print(\"Factorized dataset:\")\n",
        "print(df)\n",
        "\n",
        "# Build the ID3 decision tree\n",
        "tree = id3(df, \"PlayTennis\", attribute_names)\n",
        "\n",
        "# Print the resulting tree structure\n",
        "print(\"The tree structure:\")\n",
        "pprint(tree)\n",
        "\n",
        "# Define a new sample to classify\n",
        "new_sample = {\n",
        "    \"Outlook\": \"Sunny\",\n",
        "    \"Temperature\": \"Hot\",\n",
        "    \"Humidity\": \"High\",\n",
        "    \"Windy\": \"FALSE\"\n",
        "}\n",
        "\n",
        "# Factorize the new sample based on the existing factor mappings\n",
        "for colname in new_sample:\n",
        "    new_sample[colname] = factor_mappings[colname].tolist().index(new_sample[colname])\n",
        "\n",
        "# Classify the new sample\n",
        "classification = classify(tree, new_sample)\n",
        "print(f\"The classification for the new sample is: {'Yes' if classification == 1 else 'No' if classification == 0 else 'Unknown'}\")\n",
        "\n"
      ]
    }
  ]
}